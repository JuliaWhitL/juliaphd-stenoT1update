---
title: "Sequential causal prediction"
author: "Julia Whitman"
date: "2025-10-20"
output: html_document
---

```{r setup, include=FALSE, comment=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Sequential causal prediction

- L-variables: diabetes duration
- P-variables: LDL, sex

```{r, echo=TRUE}
library(SuperLearner)
library(tidyverse)
library(cowplot)
library(ggplot2)

# Generate training & test data
#source("synthesize-t1d-jw.R")

set.seed(120825)
train <- generate_data(3200, coefficients = coefficients, dag = dag2)

set.seed(82025)
test <- generate_data(2000, coefficients = coefficients, dag = dag2)

# FIXIT --- discretize time in DGM
train$Y1 <- ifelse(train$time_cvd <=1, 1, 0)
train$Y2 <- ifelse(train$time_cvd <=2 & train$time_cvd>1, 1, 0)
train$Y3 <- ifelse(train$time_cvd <=3 & train$time_cvd>2, 1, 0)

test$Y1 <- ifelse(test$time_cvd <=1, 1, 0)
test$Y2 <- ifelse(test$time_cvd <=2 & test$time_cvd>1, 1, 0)
test$Y3 <- ifelse(test$time_cvd <=3 & test$time_cvd>2, 1, 0)
```



# Sequential prediction using T-Learner

## Fixed time horizon
- We fit a T-learners (using SuperLeaner) for t=0 -> Y1 risk
- Include statin as a covariate because we fit a full "mod" instead of separate ones for "mod_A1" and "mod_A0"
- Then created two test sets where treatment was set to 1 and 0 for all, respectively
- Predicted CVD_1 risk under each treatment strategy
- Finally, we compute the estimated CATE from the difference of the estimated risks under all-treated and none-treated
- Repeated this for intervals t=0 -> Y2 and t=0 -> Y3
- This assumes all are CVD-naive at baseline and gives the cumulative risk at each time from baseline
```{r}
### T-Learner (FIXED HORIZON) ---

SL.library <- c("SL.mean", "SL.ranger", "SL.xgboost")

## Y1 (t = 0 -> 1)
covariates_Y1 <- c("sex_male", "diabetes_duration", "LDL_0", "statins_0") 

# Prepare training data (combined treatment groups)
X_train_Y1 <- train[, covariates_Y1]

# CHECKIT---is this S-learner or T-learner?
# Train on combined data (both A=0 and A=1)
fit_Y1 <- SuperLearner(Y = train$Y1,
                       X = X_train_Y1,
                       family = binomial(),
                       SL.library = SL.library)

# Create test datasets with treatment set to 1 and 0
X_test_Y1_A1 <- test[, covariates_Y1]
X_test_Y1_A1$statins_0 <- 1  # Set treatment to 1

X_test_Y1_A0 <- test[, covariates_Y1]
X_test_Y1_A0$statins_0 <- 0  # Set treatment to 0

# Predict under each treatment regime
Y1hat_A1 <- predict(fit_Y1, newdata = X_test_Y1_A1, onlySL = TRUE)$pred
Y1hat_A0 <- predict(fit_Y1, newdata = X_test_Y1_A0, onlySL = TRUE)$pred

plot(Y1hat_A1, Y1hat_A0)
abline(0,1)

## AUC & Brier Scores
aucbs_fix_Y1 <- riskRegression::Score(list('Supermodel Y1 A0' = Y1hat_A0,
                           'Supermodel Y1 A1' = Y1hat_A1), 
                               data = test,
                               null.model = TRUE,
                               #split.method = 'cv10',
                               summary = "risk",
                               formula = Y1 ~ 1,
                               seed = 8,
                               plots = c("roc","cal"))


plotRisk(aucbs_fix_Y1)
plotROC(aucbs_fix_Y1)
plotCalibration(aucbs_fix_Y1, bandwidth = 0.01) 

# CATE --- FINISH
tau_hat_Y1 <- Y1hat_A1 - Y1hat_A0
```

```{r}
## Y2 (t = 0 -> 2)
covariates_Y2 <- c("sex_male", "diabetes_duration", "LDL_0", "statins_0")

X_train_Y2 <- train[, covariates_Y2]

fit_Y2 <- SuperLearner(Y = train$Y2,
                       X = X_train_Y2,
                       family = binomial(),
                       SL.library = SL.library)

X_test_Y2_A1 <- test[, covariates_Y2]
X_test_Y2_A1$statins_0 <- 1

X_test_Y2_A0 <- test[, covariates_Y2]
X_test_Y2_A0$statins_0 <- 0

Y2hat_A1 <- predict(fit_Y2, newdata = X_test_Y2_A1, onlySL = TRUE)$pred
Y2hat_A0 <- predict(fit_Y2, newdata = X_test_Y2_A0, onlySL = TRUE)$pred

plot(Y2hat_A1, Y2hat_A0)
abline(0,1)

## AUC & Brier Scores
aucbs_fix_Y2 <- riskRegression::Score(list('Supermodel Y2 A0' = Y2hat_A0,
                           'Supermodel Y2 A1' = Y2hat_A1), 
                               data = test,
                               null.model = TRUE,
                               #split.method = 'cv10',
                               summary = "risk",
                               formula = Y2 ~ 1,
                               seed = 8,
                               plots = c("roc","cal"))


plotRisk(aucbs_fix_Y2)
plotROC(aucbs_fix_Y2)
plotCalibration(aucbs_fix_Y2, bandwidth = 0.01) 

# CATE --- FINISH
tau_hat_Y2 <- Y2hat_A1 - Y2hat_A0
```


```{r}
## Y3 (t = 0 -> 3)
covariates_Y3 <- c("sex_male", "diabetes_duration", "LDL_0", "statins_0")

X_train_Y3 <- train[, covariates_Y3]

fit_Y3 <- SuperLearner(Y = train$Y3,
                       X = X_train_Y3,
                       family = binomial(),
                       SL.library = SL.library)

X_test_Y3_A1 <- test[, covariates_Y3]
X_test_Y3_A1$statins_0 <- 1

X_test_Y3_A0 <- test[, covariates_Y3]
X_test_Y3_A0$statins_0 <- 0

Y3hat_A1 <- predict(fit_Y3, newdata = X_test_Y3_A1, onlySL = TRUE)$pred
Y3hat_A0 <- predict(fit_Y3, newdata = X_test_Y3_A0, onlySL = TRUE)$pred

plot(Y3hat_A1, Y3hat_A0)
abline(0,1)

## AUC & Brier Scores
aucbs_fix_Y3 <- riskRegression::Score(list('Supermodel Y3 A0' = Y3hat_A0,
                           'Supermodel Y3 A1' = Y3hat_A1), 
                               data = test,
                               null.model = TRUE,
                               #split.method = 'cv10',
                               summary = "risk",
                               formula = Y3 ~ 1,
                               seed = 8,
                               plots = c("roc","cal"))


plotRisk(aucbs_fix_Y3)
plotROC(aucbs_fix_Y3)
plotCalibration(aucbs_fix_Y3, bandwidth = 0.01) 

## CATE --- FINISH
tau_hat_Y3 <- Y3hat_A1 - Y3hat_A0
```

```{r}
### Store results in test data for fixed horizon T-learner
test$Y1hat_A1 <- Y1hat_A1
test$Y1hat_A0 <- Y1hat_A0
test$pred_CATE_T_Y1 <- tau_hat_Y1

test$Y2hat_A1 <- Y2hat_A1
test$Y2hat_A0 <- Y2hat_A0
test$pred_CATE_T_Y2 <- tau_hat_Y2

test$Y3hat_A1 <- Y3hat_A1
test$Y3hat_A0 <- Y3hat_A0
test$pred_CATE_T_Y3 <- tau_hat_Y3
```


```{r}
## Save fixed horizon figures

png("figs-perform-fixed.png", width = 12, height = 12, units = "in", res = 300)
par(mfrow = c(3, 3), mar = c(4, 4, 3, 2))

# row 1: Y1
plotRisk(aucbs_fix_Y1)
plotROC(aucbs_fix_Y1)
plotCalibration(aucbs_fix_Y1, bandwidth = 0.01)

# row 2: Y2
plotRisk(aucbs_fix_Y2)
plotROC(aucbs_fix_Y2)
plotCalibration(aucbs_fix_Y2, bandwidth = 0.01)

# row 3: Y3
plotRisk(aucbs_fix_Y3)
plotROC(aucbs_fix_Y3)
plotCalibration(aucbs_fix_Y3, bandwidth = 0.01)


dev.off()

par(mfrow = c(1, 1))
```


## Relative time horizon

- We fit a T-learner (using SuperLeaner) for t=0 -> Y1 risk
- We then created two test sets where treatment was set to 1 and 0 for all, respectively
- We then predict CVD_1 risk under each treatment strategy
- Finally, we compute the estimated CATE from the difference of the estimated risks under all-treated and none-treated
- We repeat this for intervals t=1 -> Y2 and t=2 -> Y3, creating "relative" (ie. one step ahead) prediction horizons
- NOTE: filtered for patients not yet experiencing event. In Q-learner, absorbing state is used.

```{r}
### T-Learner: RELATIVE ESTIMANDS (one step ahead)

## T=0 -> Y1 (baseline to t=1) - same as fixed Y1
covariates_rel01 <- c("sex_male", "diabetes_duration", "LDL_0", "statins_0")

X_train_rel01 <- train[, covariates_rel01]

# Train model on COMBINED data
fit_Y1_rel <- SuperLearner(Y = train$Y1,
                           X = X_train_rel01,
                           family = binomial(),
                           SL.library = SL.library)

# Create counterfactual test datasets
X_test_rel01_A1 <- test[, covariates_rel01]
X_test_rel01_A1$statins_0 <- 1

X_test_rel01_A0 <- test[, covariates_rel01]
X_test_rel01_A0$statins_0 <- 0

# Predict under each treatment regime
Y1hat_A1_rel <- predict(fit_Y1_rel, newdata = X_test_rel01_A1, onlySL = TRUE)$pred
Y1hat_A0_rel <- predict(fit_Y1_rel, newdata = X_test_rel01_A0, onlySL = TRUE)$pred


## AUC & Brier Scores
aucbs_rel_Y1 <- riskRegression::Score(list('Supermodel Y1 A0' = Y1hat_A0_rel,
                           'Supermodel Y1 A1' = Y1hat_A1_rel), 
                               data = test,
                               null.model = TRUE,
                               #split.method = 'cv10',
                               summary = "risk",
                               formula = Y1 ~ 1,
                               seed = 8,
                               plots = c("roc","cal"))


plotRisk(aucbs_rel_Y1)
plotROC(aucbs_rel_Y1)
plotCalibration(aucbs_rel_Y1, bandwidth = 0.01) 


## CATE 
tau_hat_Y1_rel_t0 <- Y1hat_A1_rel - Y1hat_A0_rel
```

```{r}
## T=1 -> Y2 
# FILTER to those still at risk (Y1 == 0)
train_rel12 <- train %>% filter(Y1 == 0)
test_rel12  <- test  %>% filter(Y1 == 0)

covariates_rel12 <- c("sex_male", "diabetes_duration", "LDL_1", "statins_1")

X_train_rel12 <- train_rel12[, covariates_rel12]

# Train on combined data
fit_Y2_rel <- SuperLearner(Y = train_rel12$Y2,
                           X = X_train_rel12,
                           family = binomial(),
                           SL.library = SL.library)

# Create counterfactual test datasets
X_test_rel12_A1 <- test_rel12[, covariates_rel12]
X_test_rel12_A1$statins_1 <- 1

X_test_rel12_A0 <- test_rel12[, covariates_rel12]
X_test_rel12_A0$statins_1 <- 0

# Predict under each treatment regime
Y2hat_A1_rel <- predict(fit_Y2_rel, newdata = X_test_rel12_A1, onlySL = TRUE)$pred
Y2hat_A0_rel <- predict(fit_Y2_rel, newdata = X_test_rel12_A0, onlySL = TRUE)$pred

## AUC & Brier Scores
aucbs_rel_Y2 <- riskRegression::Score(list('Supermodel Y2 A0' = Y2hat_A0_rel,
                           'Supermodel Y2 A1' = Y2hat_A1_rel), 
                               data = test %>% filter(Y1==0),
                               null.model = TRUE,
                               #split.method = 'cv10',
                               summary = "risk",
                               formula = Y2 ~ 1,
                               seed = 8,
                               plots = c("roc","cal"))


plotRisk(aucbs_rel_Y2)
plotROC(aucbs_rel_Y2)
plotCalibration(aucbs_rel_Y2, bandwidth = 0.01) # bypass dpik()’s bandwidth estimation step

## CATE
tau_hat_Y2_rel_t1 <- Y2hat_A1_rel - Y2hat_A0_rel


```


```{r}
## T=2 -> Y3 
# FILTER to those still at risk (Y1 == 0 & Y2 == 0)
train_rel23 <- train %>% filter(Y1 == 0 & Y2 == 0)
test_rel23  <- test  %>% filter(Y1 == 0 & Y2 == 0)

covariates_rel23 <- c("sex_male", "diabetes_duration", "LDL_2", "statins_2")

X_train_rel23 <- train_rel23[, covariates_rel23]

# Train on COMBINED data
fit_Y3_rel <- SuperLearner(Y = train_rel23$Y3,
                           X = X_train_rel23,
                           family = binomial(),
                           SL.library = SL.library)

# Create counterfactual test datasets
X_test_rel23_A1 <- test_rel23[, covariates_rel23]
X_test_rel23_A1$statins_2 <- 1

X_test_rel23_A0 <- test_rel23[, covariates_rel23]
X_test_rel23_A0$statins_2 <- 0

# Predict under each treatment regime
Y3hat_A1_rel <- predict(fit_Y3_rel, newdata = X_test_rel23_A1, onlySL = TRUE)$pred
Y3hat_A0_rel <- predict(fit_Y3_rel, newdata = X_test_rel23_A0, onlySL = TRUE)$pred


## AUC & Brier Scores
aucbs_rel_Y3 <- riskRegression::Score(list('Supermodel Y3 A0' = Y3hat_A0_rel,
                           'Supermodel Y3 A1' = Y3hat_A1_rel), 
                               data = test %>% filter(Y1==0 & Y2==0),
                               null.model = TRUE,
                               #split.method = 'cv10',
                               summary = "risk",
                               formula = Y3 ~ 1,
                               seed = 8,
                               plots = c("roc","cal"))


plotRisk(aucbs_rel_Y3)
plotROC(aucbs_rel_Y3)
plotCalibration(aucbs_rel_Y3, bandwidth = 0.01) 


## CATE
tau_hat_Y3_rel_t2 <- Y3hat_A1_rel - Y3hat_A0_rel

```
```{r}
## Save relative horizon figures

png("figs-perform-relative.png", width = 12, height = 12, units = "in", res = 300)
par(mfrow = c(3, 3), mar = c(4, 4, 3, 2))

plotRisk(aucbs_rel_Y1)
plotROC(aucbs_rel_Y1)
plotCalibration(aucbs_rel_Y1, bandwidth = 0.01) 


plotRisk(aucbs_rel_Y2)
plotROC(aucbs_rel_Y2)
plotCalibration(aucbs_rel_Y2, bandwidth = 0.01)

plotRisk(aucbs_rel_Y3)
plotROC(aucbs_rel_Y3)
plotCalibration(aucbs_rel_Y3, bandwidth = 0.01) 


dev.off()

par(mfrow = c(1, 1))
```



```{r}
#####################################
# Store results
#####################################

# For T=0 -> Y1 (all test observations)
test$Y1hat_A1_rel <- Y1hat_A1_rel
test$Y1hat_A0_rel <- Y1hat_A0_rel
test$pred_CATE_T_rel01 <- tau_hat_Y1_rel_t0

# For T=1 -> Y2 (only those at risk)
test$Y2hat_A1_rel <- NA
test$Y2hat_A0_rel <- NA
test$pred_CATE_T_rel12 <- NA

test$Y2hat_A1_rel[test$Y1 == 0] <- Y2hat_A1_rel
test$Y2hat_A0_rel[test$Y1 == 0] <- Y2hat_A0_rel
test$pred_CATE_T_rel12[test$Y1 == 0] <- tau_hat_Y2_rel_t1

# For T=2 -> Y3 (only those still at risk)
test$Y3hat_A1_rel <- NA
test$Y3hat_A0_rel <- NA
test$pred_CATE_T_rel23 <- NA

test$Y3hat_A1_rel[test$Y1 == 0 & test$Y2 == 0] <- Y3hat_A1_rel
test$Y3hat_A0_rel[test$Y1 == 0 & test$Y2 == 0] <- Y3hat_A0_rel
test$pred_CATE_T_rel23[test$Y1 == 0 & test$Y2 == 0] <- tau_hat_Y3_rel_t2
```

```{r}
## Plot estimated CATEs from fixed and relative horizons

max_len <- max(
  length(tau_hat_Y1), length(tau_hat_Y2), length(tau_hat_Y3),
  length(tau_hat_Y1_rel_t0), length(tau_hat_Y2_rel_t1), length(tau_hat_Y3_rel_t2)
)

pad <- function(x, len) c(x, rep(NA, len - length(x)))

df_tau_all <- data.frame(
  ID = 1:max_len,
  tau_Y1_fixed  = pad(tau_hat_Y1, max_len),
  tau_Y2_fixed  = pad(tau_hat_Y2, max_len),
  tau_Y3_fixed  = pad(tau_hat_Y3, max_len),
  tau_Y1_rel_t0 = pad(tau_hat_Y1_rel_t0, max_len),
  tau_Y2_rel_t1 = pad(tau_hat_Y2_rel_t1, max_len),
  tau_Y3_rel_t2 = pad(tau_hat_Y3_rel_t2, max_len)
)

df_long <- df_tau_all %>%
  pivot_longer(-ID, names_to = "estimand", values_to = "tau_hat") %>%
  filter(!is.na(tau_hat)) %>%
  mutate(
    type = ifelse(grepl("fixed", estimand), "Fixed", "Relative"),
    estimand = recode(estimand,
      "tau_Y1_fixed"   = "Fixed:  t=0 → Y1",
      "tau_Y2_fixed"   = "Fixed:  t=0 → Y2",
      "tau_Y3_fixed"   = "Fixed:  t=0 → Y3",
      "tau_Y1_rel_t0"  = "Relative: t=0 → Y1",
      "tau_Y2_rel_t1"  = "Relative: t=1 → Y2",
      "tau_Y3_rel_t2"  = "Relative: t=2 → Y3"
    ),
    estimand = factor(
      estimand,
      levels = c(
        "Fixed:  t=0 → Y1", "Fixed:  t=0 → Y2", "Fixed:  t=0 → Y3",
        "Relative: t=0 → Y1", "Relative: t=1 → Y2", "Relative: t=2 → Y3"
      )
    )
  )


ggplot(df_long, aes(x = estimand, y = tau_hat, fill = type)) +
  geom_boxplot(alpha = 0.7, outlier.shape = 21, outlier.size = 1.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray40") +
  coord_flip() +
  theme_minimal(base_size = 12) +
  labs(
    x = NULL,
    y = "Estimated Conditional Average Treatment Effect (CATE)",
    fill = "Horizon Type"
  ) +
  theme(
    legend.position = "bottom",
    axis.text.y = element_text(size = 11),
    plot.title = element_text(hjust = 0.5, face = "bold")
  ) +
  scale_fill_manual(values = c("Fixed" = "#91bfdb", "Relative" = "#fee090"))

```



## Q-learner 

```{r}
library(SuperLearner)

SL.library <- c("SL.mean", "SL.ranger", "SL.xgboost")

# create absorbing state so events propegate through ---is htis right?
train <- train %>%
  mutate(
    Y2 = pmax(Y1, Y2, na.rm = TRUE),
    Y3 = pmax(Y1, Y2, Y3, na.rm = TRUE)
  )

## Stage 3---
# Covariates include baseline + treatment history + time-varying LDL
covariates_Q3 <- c("sex_male", "diabetes_duration", 
                   "LDL_0", "LDL_1", "LDL_2",
                   "statins_0", "statins_1", "statins_2")

X_train_Q3 <- train[, covariates_Q3]

# Fit SuperLearner for Q3 function
fit_Q3 <- SuperLearner(Y = train$Y3,
                       X = X_train_Q3,
                       family = binomial(),
                       SL.library = SL.library)

# Create counterfactual datasets for A2 = 0 and A2 = 1
newdat_Q3_A0 <- newdat_Q3_A1 <- train
newdat_Q3_A0$statins_2 <- 0
newdat_Q3_A1$statins_2 <- 1

# Predict under both txs
pred_Q3_A0 <- predict(fit_Q3, newdata = newdat_Q3_A0[, covariates_Q3], 
                      onlySL = TRUE)$pred
pred_Q3_A1 <- predict(fit_Q3, newdata = newdat_Q3_A1[, covariates_Q3], 
                      onlySL = TRUE)$pred

# Pseudo-outcome: minimum risk under optimal A2
train$Y2_tilde <- pmin(pred_Q3_A0, pred_Q3_A1)

# Optimal treatment at t=2
train$opt_A2 <- as.numeric(pred_Q3_A1 < pred_Q3_A0)



## Stage 2--- 
# Model Y2_tilde conditional on earlier treatments

covariates_Q2 <- c("sex_male", "diabetes_duration", 
                   "LDL_0", "LDL_1",
                   "statins_0", "statins_1")

X_train_Q2 <- train[, covariates_Q2]

# Fit SuperLearner for Q2 function (continuous pseudo-outcome)
fit_Q2 <- SuperLearner(Y = train$Y2_tilde,
                       X = X_train_Q2,
                       family = gaussian(),  # Continuous outcome
                       SL.library = SL.library)

# Create counterfactual datasets for A1 = 0 and A1 = 1
newdat_Q2_A0 <- newdat_Q2_A1 <- train
newdat_Q2_A0$statins_1 <- 0
newdat_Q2_A1$statins_1 <- 1

# Predict under both treatments
pred_Q2_A0 <- predict(fit_Q2, newdata = newdat_Q2_A0[, covariates_Q2], 
                      onlySL = TRUE)$pred
pred_Q2_A1 <- predict(fit_Q2, newdata = newdat_Q2_A1[, covariates_Q2], 
                      onlySL = TRUE)$pred

# Pseudo-outcome: minimum risk under optimal A1
train$Y1_tilde <- pmin(pred_Q2_A0, pred_Q2_A1)

# Optimal treatment at t=1
train$opt_A1 <- as.numeric(pred_Q2_A1 < pred_Q2_A0)



### STAGE 1--- 
# Model Y1_tilde from baseline
covariates_Q1 <- c("sex_male", "diabetes_duration", "LDL_0", "statins_0")

X_train_Q1 <- train[, covariates_Q1]

# Fit SuperLearner for Q1 function (continuous pseudo-outcome)
fit_Q1 <- SuperLearner(Y = train$Y1_tilde,
                       X = X_train_Q1,
                       family = gaussian(),
                       SL.library = SL.library)

# Create counterfactual datasets for A0 = 0 and A0 = 1
newdat_Q1_A0 <- newdat_Q1_A1 <- train
newdat_Q1_A0$statins_0 <- 0
newdat_Q1_A1$statins_0 <- 1

# Predict under both treatments
pred_Q1_A0 <- predict(fit_Q1, newdata = newdat_Q1_A0[, covariates_Q1], 
                      onlySL = TRUE)$pred
pred_Q1_A1 <- predict(fit_Q1, newdata = newdat_Q1_A1[, covariates_Q1], 
                      onlySL = TRUE)$pred

# Final prediction: minimum risk under optimal baseline treatment
train$predicted_risk_optimal <- pmin(pred_Q1_A0, pred_Q1_A1)

# Optimal treatment at t=0
train$opt_A0 <- as.numeric(pred_Q1_A1 < pred_Q1_A0)


## Predict on test set
# Ensure absorbing state in test set
test <- test %>%
  mutate(
    Y2 = pmax(Y1, Y2, na.rm = TRUE),
    Y3 = pmax(Y1, Y2, Y3, na.rm = TRUE)
  )

# Stage 3: Predict Q3 for test set
X_test_Q3_A0 <- X_test_Q3_A1 <- test[, covariates_Q3]
X_test_Q3_A0$statins_2 <- 0
X_test_Q3_A1$statins_2 <- 1

pred_test_Q3_A0 <- predict(fit_Q3, newdata = X_test_Q3_A0, onlySL = TRUE)$pred
pred_test_Q3_A1 <- predict(fit_Q3, newdata = X_test_Q3_A1, onlySL = TRUE)$pred
test$Y2_tilde <- pmin(pred_test_Q3_A0, pred_test_Q3_A1)
test$opt_A2 <- as.numeric(pred_test_Q3_A1 < pred_test_Q3_A0)

# Stage 2: Predict Q2 for test set
X_test_Q2_A0 <- X_test_Q2_A1 <- test[, covariates_Q2]
X_test_Q2_A0$statins_1 <- 0
X_test_Q2_A1$statins_1 <- 1

pred_test_Q2_A0 <- predict(fit_Q2, newdata = X_test_Q2_A0, onlySL = TRUE)$pred
pred_test_Q2_A1 <- predict(fit_Q2, newdata = X_test_Q2_A1, onlySL = TRUE)$pred
test$Y1_tilde <- pmin(pred_test_Q2_A0, pred_test_Q2_A1)
test$opt_A1 <- as.numeric(pred_test_Q2_A1 < pred_test_Q2_A0)

# Stage 1: Predict Q1 for test set (final prediction)
X_test_Q1_A0 <- X_test_Q1_A1 <- test[, covariates_Q1]
X_test_Q1_A0$statins_0 <- 0
X_test_Q1_A1$statins_0 <- 1

pred_test_Q1_A0 <- predict(fit_Q1, newdata = X_test_Q1_A0, onlySL = TRUE)$pred
pred_test_Q1_A1 <- predict(fit_Q1, newdata = X_test_Q1_A1, onlySL = TRUE)$pred

# Final Q-learning prediction
test$predicted_risk_qlearning <- pmin(pred_test_Q1_A0, pred_test_Q1_A1)
test$opt_A0 <- as.numeric(pred_test_Q1_A1 < pred_test_Q1_A0)

### Q-learn final predictions ---
test$Qlearn_risk_A0 <- pred_test_Q1_A0  # Risk if A0=0 (w/ optimal future)
test$Qlearn_risk_A1 <- pred_test_Q1_A1  # Risk if A0=1 
test$Qlearn_risk_optimal <- pmin(pred_test_Q1_A0, pred_test_Q1_A1)
test$Qlearn_tau <- pred_test_Q1_A1 - pred_test_Q1_A0
```


```{r}
## plot everything to compare CATES
max_len <- max(
  length(tau_hat_Y1), length(tau_hat_Y2), length(tau_hat_Y3),
  length(tau_hat_Y1_rel_t0), length(tau_hat_Y2_rel_t1), length(tau_hat_Y3_rel_t2),
  length(test$Qlearn_tau)
)

pad <- function(x, len) c(x, rep(NA, len - length(x)))

df_tau_compare <- data.frame(
  ID = 1:max_len,
  tau_T_Y1_fixed= pad(tau_hat_Y1, max_len),
  tau_T_Y2_fixed= pad(tau_hat_Y2, max_len),
  tau_T_Y3_fixed= pad(tau_hat_Y3, max_len),
  tau_T_Y1_rel_t0= pad(tau_hat_Y1_rel_t0, max_len),
  tau_T_Y2_rel_t1 = pad(tau_hat_Y2_rel_t1, max_len),
  tau_T_Y3_rel_t2 = pad(tau_hat_Y3_rel_t2, max_len),
  tau_Qlearn= pad(test$Qlearn_tau, max_len)
)

```

```{r}
df_tau_long <- df_tau_compare %>%
  pivot_longer(-ID, names_to = "estimand", values_to = "tau_hat") %>%
  filter(!is.na(tau_hat)) %>%
  mutate(
    type = case_when(
      grepl("fixed", estimand) ~ "T-Learner (Fixed Horizon)",
      grepl("rel", estimand)   ~ "T-Learner (Relative Horizon)",
      grepl("Qlearn", estimand) ~ "Q-Learner",
      TRUE ~ "Other"
    ),
    estimand = recode(estimand,
      "tau_T_Y1_fixed"= "T-Fixed: T=0→Y1",
      "tau_T_Y2_fixed"= "T-Fixed: T=0→Y2",
      "tau_T_Y3_fixed"= "T-Fixed: T=0→Y3",
      "tau_T_Y1_rel_t0"= "T-Relative: T=0→Y1",
      "tau_T_Y2_rel_t1"= "T-Relative: T=1→Y2",
      "tau_T_Y3_rel_t2"= "T-Relative: T=2→Y3",
      "tau_Qlearn" = "Q-Learner"
    ),
    estimand = factor(estimand, levels = c(
      "T-Fixed: T=0→Y1", "T-Fixed: T=0→Y2", "T-Fixed: T=0→Y3",
      "T-Relative: T=0→Y1", "T-Relative: T=1→Y2", "T-Relative: T=2→Y3",
      "Q-Learner"
    ))
  )


ggplot(df_tau_long, aes(x = estimand, y = tau_hat, fill = type)) +
  geom_boxplot(alpha = 0.7, outlier.shape = 21, outlier.size = 1.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  coord_flip() +
  theme_minimal(base_size = 12) +
  labs(
    x = NULL,
    y = "Estimated CATE",
    fill = "Learner Type"
  ) +
  scale_fill_manual(values = c(
    "T-Learner (Fixed Horizon)" = "#abd9e9",
    "T-Learner (Relative Horizon)" = "#ffffbf",
    "Q-Learner" = "#f46d43"
  )) +
  theme(legend.position = "bottom")

```


# Reference code 
“By hand” - a two-stage example with three covariates (X2.1,X2.2,X2.3) at the second stage and two at the first stage (X1.1,X1.2):
```{r, eval=FALSE}

### sample code from ERica M.
Q2mod.lm <- lm(Y ~ A2*A1 + A2*X2.1 + A2*X2.2 + A2*X2.3, data=my.dat)
summary(Q2mod.lm)
newdat.0 <- newdat.1 <- my.dat
newdat.0$A2 <- 0 # cloned data where no one is treated
newdat.1$A2 <- 1 # cloned data where all are treated

my.dat$Y1.tilde <- apply(cbind(
  predict(Q2mod.lm,newdat.0),
  predict(Q2mod.lm,newdat.1)), 1, max)

Q1mod.lm <- lm(Y1.tilde ~ A1*X1.1 + A1*X1.2,data=my.dat)
summary(Q1mod.lm)
```

```{r, eval=FALSE}
# # Simple GLM for t=1
# # 1. Fit separate models for treated and untreated
# fit_Y1_A1 <- glm(Y1 ~ sex_male + diabetes_duration + LDL_0, data = train[train$statins_0 == 1, ], family = "binomial")
# summary(fit_Y1_A1)
# 
# fit_Y1_A0 <- glm(Y1 ~ sex_male + diabetes_duration + LDL_0, data = train[train$statins_0 == 0, ], family = "binomial")
# summary(fit_Y1_A0)
# 
# # 2. Predict potential outcomes under each condition
# Y1hat_1 <- predict(fit_Y1_A1, newdata = test, type = "response")
# Y1hat_0 <- predict(fit_Y1_A0, newdata = test, type = "response")
# 
# # 3. Take the difference (CATE)
# tau_hat <- Y1hat_1 - Y1hat_0

## Counterfactual performance assessment (Y1) ---
# For each time point (Y1, Y2, Y3):
# 1. use T-learner predictions (Ythat_A1, Ythat_A0).
# 2. estimate treatment probability and compute IPW.
# 3. evaluate model calibration or Brier scores using these weights — this gives the counterfactual performance as if treatment status were different
```
```



